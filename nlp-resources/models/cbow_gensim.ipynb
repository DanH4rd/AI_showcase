{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "import pickle\n",
    "import torchvision.datasets as dset\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_list_from_file(filename):\n",
    "    '''\n",
    "    Function for loading words from a file, called from the get_word_list_from_dir function.\n",
    "    Args: filename - file to load words from.\n",
    "    '''\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        # return the split results, which is all the words in the file.\n",
    "        tokens = nltk.word_tokenize(f.read().lower())  \n",
    "        return tokens\n",
    "\n",
    "def get_word_list_from_dir(directory_path):\n",
    "    '''\n",
    "    Function for loading words from all *.txt files in a directory.\n",
    "    Args: directory_path - directory where the *.txt files are stored.\n",
    "    '''\n",
    "    directory = os.fsencode(directory_path)\n",
    "    text_all = []\n",
    "    for path, directories, files in tqdm(os.walk(directory), position=1):\n",
    "        for file in tqdm(files, position=0):\n",
    "            filename = os.fsdecode(file)\n",
    "            if filename.endswith(\".txt\"):\n",
    "                text_all.extend(get_word_list_from_file(os.path.join(path,filename)))\n",
    "            else:\n",
    "                continue\n",
    "    return text_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23987393\n",
      "['ciastko', 'sakiewka', 'z', 'orzech', 'składnik:', '100gram', 'masło', '150gram', 'margaryna', '350gram', 'mąka', '5', 'żółtek,', '1', 'łyżka', 'śmietana', '18%,', '150gram', 'orzech', 'włoski']\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"example_corpus_data\"\n",
    "CONTEXT_SIZE = 2  # 2 words to the left, 2 to the right\n",
    "EMDEDDING_DIM = 100\n",
    "\n",
    "raw_text = []\n",
    "\n",
    "path_name = os.path.join(DATA_DIR, 'data.pickle')\n",
    "if os.path.exists(path_name):\n",
    "    with open(path_name, 'rb') as f:\n",
    "        raw_text = pickle.load(f)\n",
    "else:\n",
    "    raw_text = get_word_list_from_dir(DATA_DIR)\n",
    "    with open(path_name, 'wb') as f:\n",
    "        pickle.dump(raw_text, f)\n",
    "\n",
    "raw_text = raw_text\n",
    "print(len(raw_text))\n",
    "print(raw_text[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=[raw_text], epochs=50, vector_size=100, window=5, min_count=1, workers=4, sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.5241254 ,  0.42368373,  0.06257143, -0.17591274, -0.16976461,\n",
       "       -1.0694007 ,  0.60494655,  0.47909427, -0.43066508, -0.3187518 ,\n",
       "       -0.08316223, -0.6879639 , -0.01231351, -0.10204956,  0.36072493,\n",
       "       -0.5379919 ,  0.32504278, -0.6980526 ,  0.36025333, -1.1260055 ,\n",
       "        0.5076809 , -0.22917123,  0.78024805, -0.07851519, -0.22857414,\n",
       "        0.41238773, -0.04523865,  0.02208736, -0.36956808, -0.06972183,\n",
       "        0.5230254 ,  0.27348298,  0.20937549, -0.30427164, -0.34388313,\n",
       "        0.14014593, -0.06998207,  0.29179287,  0.05764451, -0.29479212,\n",
       "        0.32900602, -0.14803606,  0.30954534,  0.1886388 ,  0.03757096,\n",
       "       -0.22584778, -0.46406853,  0.15664963,  0.48777917,  0.20064838,\n",
       "        0.06301374, -0.5083499 ,  0.07579345,  0.00242908, -0.26891017,\n",
       "        0.21862704,  0.2888668 ,  0.3996825 , -0.34850234,  0.14324716,\n",
       "        0.07275969, -0.18616554,  0.30536485,  0.34978428,  0.25909764,\n",
       "        0.8929001 , -0.13722323,  0.26157075, -0.99892277, -0.23640086,\n",
       "       -0.27896434,  0.37295344,  0.5993874 , -0.40523598,  0.34322095,\n",
       "        0.10667496, -0.15100975,  0.34757653,  0.40573186,  0.13632232,\n",
       "       -0.34170792, -0.05324293,  0.03324267,  0.5089184 , -0.2570869 ,\n",
       "       -0.36688557,  0.42699984,  0.37433162,  0.33469498,  0.2731887 ,\n",
       "        0.25148892,  0.4028454 , -0.4776951 ,  0.01264371,  0.9269736 ,\n",
       "        0.32225913, -0.11515089, -0.7477669 ,  0.6130305 ,  0.14674492],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['żółtek']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Todd\n",
      "[nltk_data]     Howard\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import nltk\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def do_stuff(embeds_path, df_path):\n",
    "\n",
    "    df = pd.read_csv(df_path, sep=';')\n",
    "    sentences = list(map(nltk.word_tokenize, map(lambda x: x.lower(), df['text_content'].values)))\n",
    "    # sentences[6][5:10]\n",
    "\n",
    "    model = KeyedVectors.load_word2vec_format(embeds_path, binary=False)\n",
    "\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    enc.fit([[d] for d in df['category']])\n",
    "    y = enc.transform([[d] for d in df['category']]).toarray()\n",
    "\n",
    "    X = []\n",
    "\n",
    "    for i in range(len(sentences)):\n",
    "        words = sentences[i]\n",
    "\n",
    "        words_embeds = list(map(lambda x: model[x] if x in model else np.zeros_like(model[0]), words))\n",
    "\n",
    "        doc_embed = np.average(np.array(words_embeds), axis = 0)\n",
    "        X.append(doc_embed )\n",
    "\n",
    "    X = np.array(X)\n",
    "\n",
    "    reports = []\n",
    "\n",
    "    kf = KFold(n_splits=5)\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "        clf_kfold = MLPClassifier(random_state=1, max_iter=300).fit(X[train_index], y[train_index])\n",
    "        reports.append(classification_report(\n",
    "            y[test_index], clf_kfold.predict(X[test_index]), \n",
    "            target_names=enc.categories_[0], output_dict = True))\n",
    "        \n",
    "    total_result = dict()\n",
    "\n",
    "    for k in reports[0].keys():\n",
    "        vals = [dc[k] for dc in reports]\n",
    "\n",
    "        metrics_dict = dict()\n",
    "        for k2 in vals[0].keys():\n",
    "            vals2 = [dc[k2] for dc in vals]\n",
    "            avg_val = (sum(vals2) * 1.) / len(vals2)\n",
    "            metrics_dict[k2] = avg_val\n",
    "\n",
    "        total_result[k] = metrics_dict\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    return pd.DataFrame(total_result).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ciasta i torty</th>\n",
       "      <td>0.711383</td>\n",
       "      <td>0.643646</td>\n",
       "      <td>0.664700</td>\n",
       "      <td>771.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ciasteczka</th>\n",
       "      <td>0.655591</td>\n",
       "      <td>0.525151</td>\n",
       "      <td>0.535185</td>\n",
       "      <td>456.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desery</th>\n",
       "      <td>0.602146</td>\n",
       "      <td>0.561531</td>\n",
       "      <td>0.555538</td>\n",
       "      <td>788.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grill</th>\n",
       "      <td>0.578675</td>\n",
       "      <td>0.434738</td>\n",
       "      <td>0.469566</td>\n",
       "      <td>147.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inne</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>97.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>napoje i koktajle</th>\n",
       "      <td>0.752804</td>\n",
       "      <td>0.553552</td>\n",
       "      <td>0.626673</td>\n",
       "      <td>137.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obiady</th>\n",
       "      <td>0.672359</td>\n",
       "      <td>0.608628</td>\n",
       "      <td>0.631821</td>\n",
       "      <td>1137.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pieczywo</th>\n",
       "      <td>0.296970</td>\n",
       "      <td>0.079266</td>\n",
       "      <td>0.125022</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>przekąski</th>\n",
       "      <td>0.468530</td>\n",
       "      <td>0.172222</td>\n",
       "      <td>0.247228</td>\n",
       "      <td>480.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>przetwory</th>\n",
       "      <td>0.707218</td>\n",
       "      <td>0.535242</td>\n",
       "      <td>0.600770</td>\n",
       "      <td>234.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sałatki i surówki</th>\n",
       "      <td>0.716909</td>\n",
       "      <td>0.640027</td>\n",
       "      <td>0.658790</td>\n",
       "      <td>762.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sosy</th>\n",
       "      <td>0.490314</td>\n",
       "      <td>0.312272</td>\n",
       "      <td>0.374753</td>\n",
       "      <td>205.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zupy</th>\n",
       "      <td>0.778327</td>\n",
       "      <td>0.591452</td>\n",
       "      <td>0.668095</td>\n",
       "      <td>359.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>śniadanie</th>\n",
       "      <td>0.250573</td>\n",
       "      <td>0.058237</td>\n",
       "      <td>0.094001</td>\n",
       "      <td>92.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.670070</td>\n",
       "      <td>0.536467</td>\n",
       "      <td>0.595196</td>\n",
       "      <td>5706.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.548700</td>\n",
       "      <td>0.408283</td>\n",
       "      <td>0.446582</td>\n",
       "      <td>5706.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.675657</td>\n",
       "      <td>0.536467</td>\n",
       "      <td>0.576935</td>\n",
       "      <td>5706.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samples avg</th>\n",
       "      <td>0.514417</td>\n",
       "      <td>0.536467</td>\n",
       "      <td>0.521724</td>\n",
       "      <td>5706.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   precision    recall  f1-score  support\n",
       "ciasta i torty      0.711383  0.643646  0.664700    771.4\n",
       "ciasteczka          0.655591  0.525151  0.535185    456.0\n",
       "desery              0.602146  0.561531  0.555538    788.8\n",
       "grill               0.578675  0.434738  0.469566    147.8\n",
       "inne                0.000000  0.000000  0.000000     97.8\n",
       "napoje i koktajle   0.752804  0.553552  0.626673    137.4\n",
       "obiady              0.672359  0.608628  0.631821   1137.8\n",
       "pieczywo            0.296970  0.079266  0.125022     34.0\n",
       "przekąski           0.468530  0.172222  0.247228    480.4\n",
       "przetwory           0.707218  0.535242  0.600770    234.4\n",
       "sałatki i surówki   0.716909  0.640027  0.658790    762.8\n",
       "sosy                0.490314  0.312272  0.374753    205.8\n",
       "zupy                0.778327  0.591452  0.668095    359.8\n",
       "śniadanie           0.250573  0.058237  0.094001     92.4\n",
       "micro avg           0.670070  0.536467  0.595196   5706.6\n",
       "macro avg           0.548700  0.408283  0.446582   5706.6\n",
       "weighted avg        0.675657  0.536467  0.576935   5706.6\n",
       "samples avg         0.514417  0.536467  0.521724   5706.6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = do_stuff('data/kgr10.plain.lemma.cbow.dim100.neg10.vec',  'data/final_recipes.csv')\n",
    "out.to_csv('outs/fast_text_clarin.csv')\n",
    "out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
